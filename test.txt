See	discussions,	stats,	and	author	profiles	for	this	publication	at:	https://www.researchgate.net/publication/310461452

Classification	of	Urban	Point	Clouds:	A	Robust
Supervised	Approach	With	Automatically
Generating	Training	Data

Article		in		IEEE	Journal	of	Selected	Topics	in	Applied	Earth	Observations	and	Remote	Sensing	¡¤	March	2017

DOI:	10.1109/JSTARS.2016.2628399

CITATIONS

0

6	authors,	including:

READS

239

Zhuqiang	Li
Beijing	Normal	University

3	PUBLICATIONS			3	CITATIONS			

SEE	PROFILE

Tian	Fang

30	PUBLICATIONS			440	CITATIONS			

SEE	PROFILE

Liqiang	Zhang
Beijing	Normal	University

69	PUBLICATIONS			588	CITATIONS			

SEE	PROFILE

Zhenxin	Zhang
Capital	Normal	University

6	PUBLICATIONS			19	CITATIONS			

SEE	PROFILE

Some	of	the	authors	of	this	publication	are	also	working	on	these	related	projects:

Deep	learning	based	recognition	of	point	clouds	View	project

All	content	following	this	page	was	uploaded	by	Liqiang	Zhang	on	30	November	2016.

The	user	has	requested	enhancement	of	the	downloaded	file.

1 

Classification of urban point clouds: A robust 
supervised approach with automatically 
generating training data 

Zhuqiang Li, Liqiang Zhang, Ruofei Zhong, Tian Fang, Liang Zhang, Zhenxin Zhang 

Article

Consistent Semantic Annotation of Outdoor Datasets
via 2D/3D Label Transfer

Radim Tylecek * ID and Robert B. Fisher ID

School of Informatics, University of Edinburgh, Edinburgh EH8 9AB, UK; rbf@inf.ed.ac.uk
* Correspondence: rtylecek@inf.ed.ac.uk; Tel.: +44-756-189-9409

Received: 7 June 2018; Accepted: 4 July 2018; Published: 12 July 2018

Abstract: The advance of scene understanding methods based on machine learning relies on the
availability of large ground truth datasets, which are essential for their training and evaluation.
Construction of such datasets with imagery from real sensor data however typically requires much
manual annotation of semantic regions in the data, delivered by substantial human labour. To speed up
this process, we propose a framework for semantic annotation of scenes captured by moving camera(s),
e.g., mounted on a vehicle or robot. It makes use of an available 3D model of the traversed scene to
project segmented 3D objects into each camera frame to obtain an initial annotation of the associated 2D
image, which is followed by manual refinement by the user. The refined annotation can be transferred
to the next consecutive frame using optical flow estimation. We have evaluated the efficiency of the
proposed framework during the production of a labelled outdoor dataset. The analysis of annotation
times shows that up to 43% less effort is required on average, and the consistency of the labelling is
also improved.

Keywords: semantic annotation; ground truth; dataset; 3D; moving cameras

1. Introduction

